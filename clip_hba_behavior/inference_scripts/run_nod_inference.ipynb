{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537ca7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.nod_inference_pipeline import run_behavior_inference\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4e8c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 training run directories:\n",
      "  - random_target_e2_l10 (start epoch: 2, length: 10)\n",
      "  - random_target_e2_l2 (start epoch: 2, length: 2)\n",
      "  - random_target_e2_l20 (start epoch: 2, length: 20)\n",
      "  - random_target_e2_l30 (start epoch: 2, length: 30)\n",
      "  - random_target_e2_l40 (start epoch: 2, length: 40)\n",
      "  - random_target_e2_l5 (start epoch: 2, length: 5)\n",
      "  - random_target_e70_l10 (start epoch: 70, length: 10)\n",
      "  - random_target_e70_l2 (start epoch: 70, length: 2)\n",
      "  - random_target_e70_l20 (start epoch: 70, length: 20)\n",
      "  - random_target_e70_l30 (start epoch: 70, length: 30)\n",
      "  - random_target_e70_l40 (start epoch: 70, length: 40)\n",
      "  - random_target_e70_l5 (start epoch: 70, length: 5)\n",
      "  - random_target_e7_l2 (start epoch: 7, length: 2)\n",
      "  - random_target_e7_l20 (start epoch: 7, length: 20)\n",
      "  - random_target_e7_l30 (start epoch: 7, length: 30)\n",
      "  - random_target_e7_l40 (start epoch: 7, length: 40)\n",
      "  - random_target_e7_l5 (start epoch: 7, length: 5)\n"
     ]
    }
   ],
   "source": [
    "results_dir = Path('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "295fc117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 training run directories:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# list all training run directories in the results_dir\n",
    "run_dirs = sorted([d for d in results_dir.iterdir() \n",
    "                  if d.is_dir()\n",
    "                  and d.name.startswith('random_target')])\n",
    "\n",
    "print(f\"Found {len(run_dirs)} training run directories:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed43096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - random_target_e2_l10 (start epoch: 2, length: 10)\n",
      "  - random_target_e2_l2 (start epoch: 2, length: 2)\n",
      "  - random_target_e2_l20 (start epoch: 2, length: 20)\n",
      "  - random_target_e2_l30 (start epoch: 2, length: 30)\n",
      "  - random_target_e2_l40 (start epoch: 2, length: 40)\n",
      "  - random_target_e2_l5 (start epoch: 2, length: 5)\n",
      "  - random_target_e70_l10 (start epoch: 70, length: 10)\n",
      "  - random_target_e70_l2 (start epoch: 70, length: 2)\n",
      "  - random_target_e70_l20 (start epoch: 70, length: 20)\n",
      "  - random_target_e70_l30 (start epoch: 70, length: 30)\n",
      "  - random_target_e70_l40 (start epoch: 70, length: 40)\n",
      "  - random_target_e70_l5 (start epoch: 70, length: 5)\n",
      "  - random_target_e7_l2 (start epoch: 7, length: 2)\n",
      "  - random_target_e7_l20 (start epoch: 7, length: 20)\n",
      "  - random_target_e7_l30 (start epoch: 7, length: 30)\n",
      "  - random_target_e7_l40 (start epoch: 7, length: 40)\n",
      "  - random_target_e7_l5 (start epoch: 7, length: 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for run_dir in run_dirs:\n",
    "    # the epoch number is the second to last part of the directory name\n",
    "    epoch_part = run_dir.name.split('_')[-2]\n",
    "    epoch_number = int(epoch_part.lstrip('e'))\n",
    "    # the perturbation length is the last part of the directory name\n",
    "    length_part = run_dir.name.split('_')[-1]  \n",
    "    perturbation_length = int(length_part.lstrip('l'))\n",
    "    print(f\"  - {run_dir.name} (start epoch: {epoch_number}, length: {perturbation_length})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a16c987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e2_l2'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e2_l5'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e2_l10'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e2_l20'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e2_l30'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e2_l40'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e7_l2'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e7_l5'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e7_l20'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e7_l30'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e7_l40'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e70_l2'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e70_l5'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e70_l10'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e70_l20'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e70_l30'), PosixPath('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/perturb_length_experiments/random_target_e70_l40')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sort the run_dirs by the epoch number, then by the perturbation length\n",
    "run_dirs = sorted(run_dirs, key=lambda x: (int(x.name.split('_')[-2].lstrip('e')), int(x.name.split('_')[-1].lstrip('l'))))\n",
    "\n",
    "print(run_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b76724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ad3ee",
   "metadata": {},
   "source": [
    "Training runs from the perturbation length experiments that did not save dora parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20251024_165337 - 20251026_001111\n",
    "\n",
    "# 20251030_002338 - 20251030_063117"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f2e7f",
   "metadata": {},
   "source": [
    "Training runs from the perturbation experiments that saved their dora parameters at every epoch: 20251021_140839 - 20251023_122949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "619c9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 timestamp directories:\n"
     ]
    }
   ],
   "source": [
    "results_dir = Path('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops')\n",
    "\n",
    "# list all the run directories in the results_dir between 20251021_140839 and 20251023_122949\n",
    "run_folders = sorted([d for d in results_dir.iterdir() \n",
    "                  if d.is_dir()\n",
    "                  and d.name.startswith('20')  # Filter out 'logs' and other non-timestamp dirs\n",
    "                  and d.name >= '20251021_140839' \n",
    "                  and d.name <= '20251023_122949'])\n",
    "\n",
    "print(f\"Found {len(run_folders)} timestamp directories:\")\n",
    "for run_dir in run_folders:\n",
    "    print(f\"  - {run_dir.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1163b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dirs = []\n",
    "\n",
    "for run_dir in run_folders:\n",
    "    results_dir = run_dir / 'output'\n",
    "    if not results_dir.exists():\n",
    "        print(f\"Skipping {run_dir.name}: output directory not found\")\n",
    "        continue\n",
    "    else: \n",
    "        # select the folder in the results_dir that starts with 'random_target'\n",
    "        random_target_dir = next((d for d in results_dir.iterdir() if d.name.startswith('random_target')), None)\n",
    "        if random_target_dir is None:\n",
    "            print(f\"Skipping {run_dir.name}: no random_target* directory found\")\n",
    "            continue\n",
    "        run_dirs.append(random_target_dir)\n",
    "        if random_target_dir:\n",
    "            # the epoch number is the second to last part of the directory name, but only the integer part\n",
    "            epoch_part = random_target_dir.name.split('_')[-2]\n",
    "            epoch_number = int(epoch_part.lstrip('e'))\n",
    "            # the perturbation length is the last part of the directory name, but only the integer part\n",
    "            length_part = random_target_dir.name.split('_')[-1]  \n",
    "            perturbation_length = int(length_part.lstrip('l'))  \n",
    "            print(f\"Processing perturbation experiment starting at epoch {epoch_number} with perturbation length {perturbation_length}\")\n",
    "            # Run inference with configuration\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec45a857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# sort the run_dirs by the epoch number, then by the perturbation length\n",
    "run_dirs = [d for d in run_dirs if d is not None]\n",
    "run_dirs = sorted(run_dirs, key=lambda x: (int(x.name.split('_')[-2].lstrip('e')), int(x.name.split('_')[-1].lstrip('l'))))\n",
    "print(run_dirs)\n",
    "\n",
    "for run_dir in run_dirs:\n",
    "    print(run_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d1826",
   "metadata": {},
   "source": [
    "Run inference with Natural Object Dataset (NOD) images on the models from the single epoch perturbation sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305cb7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 training runs:\n",
      "  - training_run1\n",
      "  - training_run2\n",
      "  - training_run3\n",
      "  - training_run4\n",
      "  - training_run5\n",
      "  - training_run6\n",
      "  - training_run7\n",
      "  - training_run8\n",
      "  - training_run9\n",
      "  - training_run10\n",
      "  - training_run11\n",
      "  - training_run12\n",
      "  - training_run13\n",
      "  - training_run14\n",
      "  - training_run15\n",
      "  - training_run16\n",
      "  - training_run17\n",
      "  - training_run18\n",
      "  - training_run19\n",
      "  - training_run20\n",
      "  - training_run21\n",
      "  - training_run22\n",
      "  - training_run23\n",
      "  - training_run24\n",
      "  - training_run25\n",
      "  - training_run26\n",
      "  - training_run27\n",
      "  - training_run28\n",
      "  - training_run29\n",
      "  - training_run30\n",
      "  - training_run31\n",
      "  - training_run32\n",
      "  - training_run33\n",
      "  - training_run34\n",
      "  - training_run35\n",
      "  - training_run36\n",
      "  - training_run37\n",
      "  - training_run38\n",
      "  - training_run39\n",
      "  - training_run40\n",
      "  - training_run41\n",
      "  - training_run42\n",
      "  - training_run43\n",
      "  - training_run44\n",
      "  - training_run45\n",
      "  - training_run46\n",
      "  - training_run47\n",
      "  - training_run48\n",
      "  - training_run49\n",
      "  - training_run50\n",
      "  - training_run51\n",
      "  - training_run52\n",
      "  - training_run53\n",
      "  - training_run54\n",
      "  - training_run55\n",
      "  - training_run56\n",
      "  - training_run57\n",
      "  - training_run58\n",
      "  - training_run59\n",
      "  - training_run60\n",
      "  - training_run61\n",
      "  - training_run62\n",
      "  - training_run63\n",
      "  - training_run64\n",
      "  - training_run65\n",
      "  - training_run66\n",
      "  - training_run67\n",
      "  - training_run68\n",
      "  - training_run69\n",
      "  - training_run70\n",
      "  - training_run71\n",
      "  - training_run72\n",
      "  - training_run73\n",
      "  - training_run74\n",
      "  - training_run75\n",
      "  - training_run76\n",
      "  - training_run77\n",
      "  - training_run78\n",
      "  - training_run79\n",
      "  - training_run80\n",
      "  - training_run81\n",
      "  - training_run82\n",
      "  - training_run83\n",
      "  - training_run84\n",
      "  - training_run85\n",
      "  - training_run86\n",
      "  - training_run87\n",
      "  - training_run88\n",
      "  - training_run89\n",
      "  - training_run90\n",
      "  - training_run91\n",
      "  - training_run92\n",
      "  - training_run93\n",
      "  - training_run94\n",
      "  - training_run95\n",
      "  - training_run96\n",
      "  - training_run97\n",
      "  - training_run98\n"
     ]
    }
   ],
   "source": [
    "results_dir = Path('/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior_loops/20251016_125025')\n",
    "\n",
    "# list all the run directories in the results_dir\n",
    "run_dirs = sorted([d for d in results_dir.glob('training_run*') if d.is_dir()],\n",
    "                  key=lambda x: int(x.name.split('run')[1]))\n",
    "\n",
    "print(f\"Found {len(run_dirs)} training runs:\")\n",
    "for run_dir in run_dirs:\n",
    "    print(f\"  - {run_dir.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc19e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midpoint ordering for 98 runs: [1, 98, 49, 25, 73, 13, 37, 61, 85, 7, 19, 31, 43, 55, 67, 79, 91, 4, 10, 16, 22, 28, 34, 40, 46, 52, 58, 64, 70, 76]\n",
      "Total runs to process: 98\n"
     ]
    }
   ],
   "source": [
    "def generate_midpoint_order(num_runs):\n",
    "    \"\"\"\n",
    "    Generate a midpoint/binary search ordering for exploring training runs.\n",
    "    Starts with boundaries [1, num_runs], then fills in midpoints.\n",
    "    \"\"\"\n",
    "    visited = set()\n",
    "    ordering = []\n",
    "    queue = [(1, num_runs)]  # Start with the full range\n",
    "    \n",
    "    while queue:\n",
    "        low, high = queue.pop(0)\n",
    "        mid = (low + high) // 2\n",
    "        \n",
    "        # Process endpoints first if not already visited\n",
    "        if low not in visited:\n",
    "            ordering.append(low)\n",
    "            visited.add(low)\n",
    "        if high not in visited:\n",
    "            ordering.append(high)\n",
    "            visited.add(high)\n",
    "        \n",
    "        # Add midpoint if it exists and hasn't been visited\n",
    "        if low < mid < high and mid not in visited:\n",
    "            ordering.append(mid)\n",
    "            visited.add(mid)\n",
    "            \n",
    "            # Add sub-ranges to queue for further midpoint processing\n",
    "            if low < mid - 1:\n",
    "                queue.append((low, mid))\n",
    "            if mid < high - 1:\n",
    "                queue.append((mid, high))\n",
    "    \n",
    "    return ordering\n",
    "\n",
    "# Generate midpoint ordering for the runs\n",
    "midpoint_order = generate_midpoint_order(len(run_dirs))\n",
    "print(f\"Midpoint ordering for {len(run_dirs)} runs: {midpoint_order[:30]}\")  # Show first 30\n",
    "print(f\"Total runs to process: {len(midpoint_order)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcdee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    config = {\n",
    "        'img_dir': '/home/wallacelab/teba/multimodal_brain_inspired/NOD/imagenet',  # input images directory,\n",
    "        'category_index_file': '../analysis/sorted_file_categories.csv', \n",
    "        'load_hba': True,  # False will load the original CLIP-ViT weights\n",
    "        'backbone': 'ViT-L/14',  # CLIP backbone model\n",
    "        'model_path': '/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/clip_hba_behavior/models/cliphba_behavior_20250919_212822.pth',  # path to the final trained model\n",
    "        'batch_size': 64,  # batch size (increased for better GPU utilization)\n",
    "        'cuda': 'cuda:1',  # 'cuda:0' for GPU 0, 'cuda:1' for GPU 1, '-1' for all GPUs\n",
    "    }\n",
    "\n",
    "    # Use midpoint ordering to process runs\n",
    "    for iteration, run_index in enumerate(midpoint_order, 1):\n",
    "        run_dir = run_dirs[run_index - 1]  # Convert to 0-based index\n",
    "        run_number = run_dir.name.replace('training_run', '')\n",
    "\n",
    "        # Construct paths specific to this training run\n",
    "        dora_params_path = run_dir / f'dora_params_run{run_number}'\n",
    "        save_folder = run_dir / 'nod_inference_results'\n",
    "\n",
    "        # Check if dora params exist\n",
    "        if not dora_params_path.exists():\n",
    "            print(f\"Skipping {run_dir.name}: dora_params directory not found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing {run_dir.name} (Iteration {iteration}/{len(midpoint_order)})\")\n",
    "        print(f\"Dora params path: {dora_params_path}\")\n",
    "        print(f\"Save folder: {save_folder}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "        # Create config for this specific run\n",
    "        config['dora_params_path'] = str(dora_params_path)\n",
    "        config['save_folder'] = str(save_folder)\n",
    "\n",
    "        # Run inference with configuration\n",
    "        try:\n",
    "            run_behavior_inference(config)\n",
    "            print(f\"✓ Completed inference for {run_dir.name}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error during inference for {run_dir.name}: {e}\\n\")\n",
    "            continue\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
