{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639d2571",
   "metadata": {},
   "source": [
    "# Process fMRI RDMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7a492",
   "metadata": {},
   "source": [
    "### Load fMRI RDMs for VA-1, VA-2, VA-3, left LOC, and right LOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the files from the fmri_path directory that contain the word 'va-1', or 'va-2', or 'va-3'\n",
    "fmri_path = Path('../../THINGS_fMRI/all_rdm')\n",
    "fmri_files = list(fmri_path.glob(\"*va-1_*\")) + list(fmri_path.glob(\"*va-2_*\")) + list(fmri_path.glob(\"*va-3_*\")) + list(fmri_path.glob(\"*lLOC*\")) + list(fmri_path.glob(\"*rLOC*\"))\n",
    "\n",
    "# create a dictionary to store the fMRI RDMs\n",
    "fmri_rdms = {}\n",
    "\n",
    "for file in fmri_files:\n",
    "    # extract the subject number from the file name\n",
    "    subject_number = file.stem.split('_')[0].split('-')[1]\n",
    "    print(subject_number)\n",
    "    # extract the roi from the file name\n",
    "    # This pattern is looking for the ROI name as the second element after splitting the filename (without extension) by underscores.\n",
    "    if 'va' in file.stem:\n",
    "        roi = file.stem.split('_')[2]\n",
    "    else:\n",
    "        roi = file.stem.split('_')[1]\n",
    "    print(roi)\n",
    "    fmri_rdm = np.load(file)\n",
    "    print(fmri_rdm.shape)\n",
    "    # store the fMRI RDM in the dictionary\n",
    "    fmri_rdms[subject_number + '_' + roi] = fmri_rdm\n",
    "\n",
    "# # print the first 5x5 of every fMRI RDM in the dictionary\n",
    "for key in fmri_rdms:\n",
    "    print(key)\n",
    "    print(fmri_rdms[key][:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d89537",
   "metadata": {},
   "source": [
    "### Get the variable names for our five ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_rdms_rois = list(set([key.split('_')[1] for key in fmri_rdms.keys()]))\n",
    "\n",
    "print(fmri_rdms_rois)\n",
    "\n",
    "for roi in fmri_rdms_rois:\n",
    "    # Create a dictionary of RDMs for the current ROI, using the ROI name in the variable name\n",
    "    roi_rdms_varname = f\"{roi}_rdms\"\n",
    "    locals()[roi_rdms_varname] = {k: v for k, v in fmri_rdms.items() if roi in k}\n",
    "\n",
    "    print(roi_rdms_varname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e104d",
   "metadata": {},
   "source": [
    "### Load the concept index for the fMRI RDMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the concept index for the fMRI RDM\n",
    "\n",
    "concept_index = np.load('./concept_indices/sub-01_LOC_concept_index.npy')\n",
    "\n",
    "print(concept_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353808b",
   "metadata": {},
   "source": [
    "### Read in the Stimulus Metadata file for each subject to ensure that all subjects were shown the same 8640 images making up the 720 concepts during fMRI trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Stimulus Metadata file for each subject\n",
    "sub_01_stimulus_metadata = pd.read_csv('sub-01_StimulusMetadata_train_only.csv').sort_values(by='concept').sort_values(by='stimulus')\n",
    "\n",
    "# print the first 20 rows of the Stimulus Metadata file\n",
    "#print(sub_01_stimulus_metadata.head(20))\n",
    "\n",
    "sub_02_stimulus_metadata = pd.read_csv('sub-02_StimulusMetadata_train_only.csv').sort_values(by='concept').sort_values(by='stimulus')\n",
    "\n",
    "#print(sub_02_stimulus_metadata.head(20))\n",
    "\n",
    "sub_03_stimulus_metadata = pd.read_csv('sub-03_StimulusMetadata_train_only.csv').sort_values(by='concept').sort_values(by='stimulus')\n",
    "\n",
    "#print(sub_03_stimulus_metadata.head(20))\n",
    "\n",
    "# I want to test whether the stimulus column is exactly the same across all three subjects\n",
    "# FIXED: Use reset_index(drop=True) to compare only values, not indices\n",
    "print(\"Comparing stimulus columns (values only):\")\n",
    "print(sub_01_stimulus_metadata['stimulus'].reset_index(drop=True).equals(sub_02_stimulus_metadata['stimulus'].reset_index(drop=True)))\n",
    "print(sub_01_stimulus_metadata['stimulus'].reset_index(drop=True).equals(sub_03_stimulus_metadata['stimulus'].reset_index(drop=True)))\n",
    "print(sub_02_stimulus_metadata['stimulus'].reset_index(drop=True).equals(sub_03_stimulus_metadata['stimulus'].reset_index(drop=True)))\n",
    "\n",
    "# Find and print rows where the 'stimulus' column differs across the three subjects\n",
    "\n",
    "stim_01 = sub_01_stimulus_metadata['stimulus'].reset_index(drop=True)\n",
    "stim_02 = sub_02_stimulus_metadata['stimulus'].reset_index(drop=True)\n",
    "stim_03 = sub_03_stimulus_metadata['stimulus'].reset_index(drop=True)\n",
    "\n",
    "# Find indices where any pair is not equal\n",
    "diff_mask = ~((stim_01 == stim_02) & (stim_01 == stim_03) & (stim_02 == stim_03))\n",
    "\n",
    "# Print the differing rows\n",
    "if diff_mask.any():\n",
    "    print(\"Rows where 'stimulus' column differs across subjects:\")\n",
    "    diff_df = pd.DataFrame({\n",
    "        'row': stim_01.index[diff_mask],\n",
    "        'sub_01_stimulus': stim_01[diff_mask].values,\n",
    "        'sub_02_stimulus': stim_02[diff_mask].values,\n",
    "        'sub_03_stimulus': stim_03[diff_mask].values\n",
    "    })\n",
    "    print(diff_df)\n",
    "else:\n",
    "    print(\"No differences found in the 'stimulus' column across the three subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ac605",
   "metadata": {},
   "source": [
    "### We can safely say that all three subjects were shown the same 12 images across all 720 object concepts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fcebe",
   "metadata": {},
   "source": [
    "### Calculate the average concept RDM for each ROI across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b013f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create averaged upper triangle vectors for all ROIs\n",
    "# First, identify all unique ROIs from the fmri_rdms dictionary\n",
    "rois = set()\n",
    "for key in fmri_rdms.keys():\n",
    "    roi = key.split('_')[1]  # Extract ROI from key like '01_lLOC' -> 'lLOC'\n",
    "    rois.add(roi)\n",
    "\n",
    "print(\"Available ROIs:\", sorted(rois))\n",
    "\n",
    "# Create a dictionary to store averaged upper triangle vectors for each ROI\n",
    "roi_average_upper_triangles = {}\n",
    "\n",
    "# Get upper triangular indices (same for all RDMs since they're all 720x720)\n",
    "upper_tri_indices = np.triu_indices_from(fmri_rdms[list(fmri_rdms.keys())[0]], k=1)\n",
    "\n",
    "for roi in sorted(rois):\n",
    "    print(f\"\\nProcessing ROI: {roi}\")\n",
    "    \n",
    "    # Filter RDMs for this specific ROI\n",
    "    roi_rdms = {k: v for k, v in fmri_rdms.items() if roi in k}\n",
    "    print(f\"Found {len(roi_rdms)} RDMs for {roi}\")\n",
    "    \n",
    "    # Extract upper triangular elements for each RDM\n",
    "    roi_rdms_upper = {}\n",
    "    for key in roi_rdms:\n",
    "        roi_rdms_upper[key] = roi_rdms[key][upper_tri_indices]\n",
    "    \n",
    "    # Stack the vectors into a single array\n",
    "    roi_rdms_upper_array = np.stack(list(roi_rdms_upper.values()))\n",
    "    print(f\"Stacked array shape: {roi_rdms_upper_array.shape}\")\n",
    "    \n",
    "    # Calculate the average across subjects\n",
    "    # axis=0 means we are taking the mean down the rows (i.e., column-wise), so for each position in the upper triangle vector, we average across all subjects' RDMs\n",
    "    roi_average_upper_triangle = np.mean(roi_rdms_upper_array, axis=0)\n",
    "    print(f\"Average vector shape: {roi_average_upper_triangle.shape}\")\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    roi_average_upper_triangles[roi] = roi_average_upper_triangle\n",
    "    \n",
    "    # Print first 5 values as a sanity check\n",
    "    print(f\"First 5 values for {roi}: {roi_average_upper_triangle[:5]}\")\n",
    "\n",
    "print(f\"\\nCreated averaged upper triangle vectors for {len(roi_average_upper_triangles)} ROIs:\")\n",
    "for roi in roi_average_upper_triangles:\n",
    "    print(f\"  {roi}: shape {roi_average_upper_triangles[roi].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe09eb",
   "metadata": {},
   "source": [
    "### Average the fMRI activity between left and right LOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ca914",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_average_upper_triangles['LOC'] = np.mean(\n",
    "    np.stack([roi_average_upper_triangles['lLOC'], roi_average_upper_triangles['rLOC']]), axis=0\n",
    ")\n",
    "\n",
    "print(roi_average_upper_triangles['LOC'].shape)\n",
    "\n",
    "print(roi_average_upper_triangles['rLOC'].shape)\n",
    "\n",
    "print(roi_average_upper_triangles.keys())\n",
    "\n",
    "# remove the lLOC and rLOC keys\n",
    "roi_average_upper_triangles.pop('lLOC')\n",
    "roi_average_upper_triangles.pop('rLOC')\n",
    "\n",
    "print(roi_average_upper_triangles.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2764b4",
   "metadata": {},
   "source": [
    "# Create feature-reweighting functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec711f",
   "metadata": {},
   "source": [
    "### Convert the vectors of fMRI RDMs averaged across subjects for each ROI back to 720x720 RDMs to ensure proper formatting for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert upper triangular vectors back to 720x720 RDMs (CORRECTED VERSION)\n",
    "# This reconstructs the full RDM matrices from the upper triangular elements\n",
    "\n",
    "# Dictionary to store reconstructed RDMs\n",
    "roi_reconstructed_rdms = {}\n",
    "\n",
    "print(\"Reconstructing 720x720 RDMs from upper triangular vectors (CORRECTED)...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the upper triangular indices (same as used before)\n",
    "upper_tri_indices = np.triu_indices(720, k=1)  # 720x720 matrix, k=1 excludes diagonal\n",
    "\n",
    "print(f\"Upper triangular indices shape: {upper_tri_indices[0].shape}\")\n",
    "print(f\"Number of upper triangular elements: {len(upper_tri_indices[0])}\")\n",
    "print(f\"Expected vector length: {len(upper_tri_indices[0])}\")\n",
    "\n",
    "# Loop through each ROI\n",
    "for roi in sorted(roi_average_upper_triangles.keys()):\n",
    "    print(f\"\\nProcessing ROI: {roi}\")\n",
    "    \n",
    "    # Get the upper triangular vector\n",
    "    upper_tri_vector = roi_average_upper_triangles[roi]\n",
    "    print(f\"  Upper triangular vector shape: {upper_tri_vector.shape}\")\n",
    "    print(f\"  Vector length: {len(upper_tri_vector)}\")\n",
    "    \n",
    "    # Verify the vector length matches expected\n",
    "    expected_length = len(upper_tri_indices[0])\n",
    "    if len(upper_tri_vector) != expected_length:\n",
    "        print(f\"  ⚠ Warning: Vector length {len(upper_tri_vector)} doesn't match expected {expected_length}\")\n",
    "    else:\n",
    "        print(f\"  ✓ Vector length matches expected\")\n",
    "    \n",
    "    # Create empty RDM matrix\n",
    "    rdm = np.zeros((720, 720))\n",
    "    \n",
    "    # Fill the upper triangular part\n",
    "    rdm[upper_tri_indices] = upper_tri_vector\n",
    "    \n",
    "    # Fill the lower triangular part (RDM is symmetric) - CORRECTED METHOD\n",
    "    # Use transpose to ensure perfect symmetry\n",
    "    rdm = rdm + rdm.T\n",
    "    \n",
    "    # Ensure diagonal is zero\n",
    "    np.fill_diagonal(rdm, 0)\n",
    "    \n",
    "    # Store the reconstructed RDM\n",
    "    roi_reconstructed_rdms[roi] = rdm\n",
    "    \n",
    "    print(f\"  Reconstructed RDM shape: {rdm.shape}\")\n",
    "    print(f\"  RDM is symmetric: {np.allclose(rdm, rdm.T)}\")\n",
    "    print(f\"  Diagonal is zero: {np.all(np.diag(rdm) == 0)}\")\n",
    "    print(f\"  Min value: {np.min(rdm):.4f}\")\n",
    "    print(f\"  Max value: {np.max(rdm):.4f}\")\n",
    "    print(f\"  Mean value: {np.mean(rdm):.4f}\")\n",
    "\n",
    "print(f\"\\nSuccessfully reconstructed RDMs for {len(roi_reconstructed_rdms)} ROIs\")\n",
    "print(f\"Available ROIs: {sorted(roi_reconstructed_rdms.keys())}\")\n",
    "\n",
    "# Verify reconstruction by comparing with original data\n",
    "print(f\"\\nReconstruction verification:\")\n",
    "for roi in sorted(roi_reconstructed_rdms.keys()):\n",
    "    reconstructed_rdm = roi_reconstructed_rdms[roi]\n",
    "    original_vector = roi_average_upper_triangles[roi]\n",
    "    \n",
    "    # Extract upper triangular from reconstructed RDM\n",
    "    reconstructed_vector = reconstructed_rdm[upper_tri_indices]\n",
    "    \n",
    "    # Check if they match\n",
    "    vectors_match = np.allclose(original_vector, reconstructed_vector)\n",
    "    print(f\"  {roi}: Vectors match = {vectors_match}\")\n",
    "    \n",
    "    if not vectors_match:\n",
    "        diff = np.abs(original_vector - reconstructed_vector)\n",
    "        print(f\"    Max difference: {np.max(diff):.10f}\")\n",
    "        print(f\"    Mean difference: {np.mean(diff):.10f}\")\n",
    "\n",
    "# Show how to access the reconstructed RDMs\n",
    "print(f\"\\nExample usage:\")\n",
    "first_roi = sorted(roi_reconstructed_rdms.keys())[0]\n",
    "print(f\"  roi_reconstructed_rdms['{first_roi}']  # 720x720 RDM for {first_roi}\")\n",
    "print(f\"  roi_reconstructed_rdms['{first_roi}'][:5, :5]  # First 5x5 of the RDM\")\n",
    "\n",
    "# Show a sample of the reconstructed RDM\n",
    "sample_roi = sorted(roi_reconstructed_rdms.keys())[0]\n",
    "sample_rdm = roi_reconstructed_rdms[sample_roi]\n",
    "print(f\"\\nSample RDM ({sample_roi}) - first 5x5:\")\n",
    "print(sample_rdm[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafba3a",
   "metadata": {},
   "source": [
    "### Define a function that uses ridge regression to generate weights for combining the 14 layer-level RDMs to predict a single neural RDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f365d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_reweighting_single_rdm(\n",
    "    model_rdms,  # Shape: [L, N, N]\n",
    "    neural_rdm,   # Shape: [N, N] - single RDM\n",
    "    alpha_candidates=None,\n",
    "    cv_folds=5,\n",
    "    objective='spearman'\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute ridge weights combining layer model RDMs to predict a single neural RDM.\n",
    "    \n",
    "    Args:\n",
    "        model_rdms: Model RDMs of shape [L, N, N]\n",
    "        neural_rdm: Single neural RDM of shape [N, N]\n",
    "        alpha_candidates: List of alpha values to test\n",
    "        cv_folds: Number of cross-validation folds\n",
    "        objective: 'spearman' or 'ridgecv'\n",
    "        \n",
    "    Returns:\n",
    "        weights: Ridge weights of shape [L] - one weight per layer\n",
    "        best_alpha: Best alpha value found\n",
    "        cv_score: Cross-validation score\n",
    "    \"\"\"\n",
    "\n",
    "    L, N, _ = model_rdms.shape\n",
    "    \n",
    "    # Build feature matrix X = upper-tri of each layer RDM -> [n_pairs, L]\n",
    "    triu = torch.triu_indices(N, N, offset=1)\n",
    "    n_pairs = triu.shape[1]\n",
    "    X = np.zeros((n_pairs, L), dtype=np.float32)\n",
    "    \n",
    "    for l in range(L):\n",
    "        rdm_l = model_rdms[l]\n",
    "        X[:, l] = rdm_l[triu[0], triu[1]].astype(np.float32)\n",
    "    \n",
    "    # Extract target vector from neural RDM\n",
    "    if isinstance(neural_rdm, torch.Tensor):\n",
    "        y = neural_rdm[triu[0], triu[1]].cpu().numpy().astype(np.float32)\n",
    "    else:\n",
    "        y = neural_rdm[triu[0], triu[1]].astype(np.float32)\n",
    "    \n",
    "    alpha_candidates = alpha_candidates if alpha_candidates is not None else [1e-3, 1e-2, 1e-1, 1.0, 1e1, 1e2, 1e3]\n",
    "    \n",
    "    # Cross-validation to find best alpha\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=0)\n",
    "    best_alpha = None\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    print(f\"Cross-validating {len(alpha_candidates)} alpha values with {cv_folds} folds...\")\n",
    "\n",
    "    for alpha in tqdm(alpha_candidates, desc=\"Cross-validating alphas\"):\n",
    "        fold_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_tr, X_val = X[train_idx], X[val_idx]\n",
    "            y_tr, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            if objective == 'spearman':\n",
    "                # Rank-transform targets and center\n",
    "                y_tr_rank = stats.rankdata(y_tr).astype(np.float32)\n",
    "                y_tr_rank -= y_tr_rank.mean()\n",
    "                \n",
    "                model = Ridge(alpha=alpha, fit_intercept=False)\n",
    "                model.fit(X_tr, y_tr_rank)\n",
    "                y_val_pred = X_val @ model.coef_.astype(np.float32)\n",
    "                \n",
    "                rho, _ = stats.spearmanr(y_val_pred, y_val)\n",
    "                if np.isnan(rho):\n",
    "                    rho = 0.0\n",
    "                fold_scores.append(float(rho))\n",
    "\n",
    "            else:  # ridgecv objective\n",
    "                # Center targets\n",
    "                y_tr_centered = y_tr - y_tr.mean()\n",
    "                y_val_centered = y_val - y_val.mean()\n",
    "                \n",
    "                model = Ridge(alpha=alpha, fit_intercept=False)\n",
    "                model.fit(X_tr, y_tr_centered)\n",
    "                y_val_pred = X_val @ model.coef_.astype(np.float32)\n",
    "                \n",
    "                # R² score\n",
    "                ss_res = np.sum((y_val_centered - y_val_pred)**2)\n",
    "                ss_tot = np.sum((y_val_centered - y_val_centered.mean())**2) + 1e-12\n",
    "                r2 = 1.0 - ss_res/ss_tot\n",
    "                fold_scores.append(float(r2))\n",
    "        \n",
    "        mean_score = float(np.mean(fold_scores))\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_alpha = float(alpha)\n",
    "\n",
    "    # Refit on full data with best alpha\n",
    "    if objective == 'spearman':\n",
    "        y_rank = stats.rankdata(y).astype(np.float32)\n",
    "        y_rank -= y_rank.mean()\n",
    "        final_model = Ridge(alpha=best_alpha, fit_intercept=False)\n",
    "        final_model.fit(X, y_rank)\n",
    "        weights = torch.from_numpy(final_model.coef_.astype(np.float32))\n",
    "    else:\n",
    "        y_centered = y - y.mean()\n",
    "        final_model = Ridge(alpha=best_alpha, fit_intercept=False)\n",
    "        final_model.fit(X, y_centered)\n",
    "        weights = torch.from_numpy(final_model.coef_.astype(np.float32))\n",
    "    \n",
    "    print(f\"Best alpha: {best_alpha}\")\n",
    "    print(f\"CV score: {best_score:.4f}\")\n",
    "    \n",
    "    return weights, best_alpha, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488117e6",
   "metadata": {},
   "source": [
    "### Define a function that computes a feature-reweighted model RDM from the ridge weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa95779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reweighted_predictor(\n",
    "    model_rdms,  # Shape: [L, N, N]\n",
    "    weights     # Shape: [L] - ridge weights\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the reweighted predictor RDM by combining model RDMs with ridge weights.\n",
    "    \n",
    "    Args:\n",
    "        model_rdms: Model RDMs of shape [L, N, N]\n",
    "        weights: Ridge weights of shape [L]\n",
    "        \n",
    "    Returns:\n",
    "        reweighted_rdm: Combined RDM of shape [N, N]\n",
    "    \"\"\"\n",
    "    L, N, _ = model_rdms.shape\n",
    "    \n",
    "    # Convert weights to numpy if needed\n",
    "    if isinstance(weights, torch.Tensor):\n",
    "        weights = weights.cpu().numpy()\n",
    "    \n",
    "    # Initialize reweighted RDM\n",
    "    reweighted_rdm = np.zeros((N, N), dtype=np.float32)\n",
    "    \n",
    "    # Weighted combination of model RDMs\n",
    "    for l in range(L):\n",
    "        reweighted_rdm += weights[l] * model_rdms[l]\n",
    "    \n",
    "    # Ensure symmetry (in case of numerical errors)\n",
    "    reweighted_rdm = (reweighted_rdm + reweighted_rdm.T) / 2\n",
    "    \n",
    "    # Set diagonal to 0 (RDMs should have 0 on diagonal)\n",
    "    np.fill_diagonal(reweighted_rdm, 0)\n",
    "\n",
    "    return reweighted_rdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dcfe91",
   "metadata": {},
   "source": [
    "### Define a function that will run the RDM feature-reweighting analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_rdm_analysis(\n",
    "    model_rdms,      # Shape: [L, N, N]\n",
    "    neural_rdm,      # Shape: [N, N]\n",
    "    alpha_candidates=None,\n",
    "    cv_folds=5,\n",
    "    objective='spearman'\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete pipeline for single RDM ridge regression analysis.\n",
    "    \n",
    "    Returns:\n",
    "        weights: Ridge weights [L]\n",
    "        best_alpha: Best alpha value\n",
    "        cv_score: Cross-validation score\n",
    "        reweighted_rdm: Predicted RDM [N, N]\n",
    "        correlation: Correlation between predicted and actual RDM\n",
    "    \"\"\"\n",
    "    print(\"Single RDM Ridge Regression Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Model RDMs shape: {model_rdms.shape}\")\n",
    "    print(f\"Neural RDM shape: {neural_rdm.shape}\")\n",
    "    print(f\"Objective: {objective}\")\n",
    "    print(f\"CV folds: {cv_folds}\")\n",
    "    \n",
    "    # Compute ridge weights\n",
    "    weights, best_alpha, cv_score = ridge_reweighting_single_rdm(\n",
    "        model_rdms, neural_rdm, alpha_candidates, cv_folds, objective\n",
    "    )\n",
    "    \n",
    "    # Compute reweighted predictor\n",
    "    reweighted_rdm = compute_reweighted_predictor(model_rdms, weights)\n",
    "\n",
    "    # Compute correlation between predicted and actual\n",
    "    # Extract upper triangular parts for correlation\n",
    "    triu = np.triu_indices(neural_rdm.shape[0], k=1)\n",
    "    neural_flat = neural_rdm[triu]\n",
    "    predicted_flat = reweighted_rdm[triu]\n",
    "    \n",
    "    if objective == 'spearman':\n",
    "        correlation, _ = stats.spearmanr(neural_flat, predicted_flat)\n",
    "    else:\n",
    "        correlation, _ = stats.pearsonr(neural_flat, predicted_flat)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"Best alpha: {best_alpha}\")\n",
    "    print(f\"CV score: {cv_score:.4f}\")\n",
    "    print(f\"Final correlation: {correlation:.4f}\")\n",
    "    print(f\"Weights: {weights.numpy()}\")\n",
    "    \n",
    "    return {\n",
    "        'weights': weights,\n",
    "        'best_alpha': best_alpha,\n",
    "        'cv_score': cv_score,\n",
    "        'reweighted_rdm': reweighted_rdm,\n",
    "        'correlation': correlation\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f7f7e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
