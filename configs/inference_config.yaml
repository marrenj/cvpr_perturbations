## ---PATHS--- ##
img_dir: "/home/wallacelab/investigating-complexity/Images/THINGS" # root directory for inference image dataset
annotations_file: "/home/wallacelab/Documents/GitHub/cvpr_perturbations/data/spose_embedding66d_rescaled_48val_reordered.csv"
inference_save_dir: "/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/test/perturb_sweep_replication/random_target_perturb_seed42/test_things_behavioral_inference"
model_weights_path: "/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/test/perturb_sweep_replication/random_target_perturb_seed42/training_artifacts/dora_params/dora_params_seed42/epoch0_dora_params.pth"

## ---MODEL PARAMETERS--- ##
backbone : ViT-L/14
vision_layers: 2
transformer_layers: 1
rank: 32
load_hba: true

## ---INFERENCE PARAMETERS--- ##
dataset: things # which dataset's inference to run (nights, nod, things)
max_images_per_category: 12
evaluation_type: behavioral # options: triplet, behavioral, neural
epoch: 1
cuda: 0 #(device selector):
batch_size: 512
num_workers: 8 # (for THINGS/NOD extraction, defaults to 8)

# ---RSA OPTIONS (used for behavioral/neural alignment)---
model_rdm_distance_metric: pearson # Either pearson or cosine distance. Generally, use pearson distance when conducting behavioral RSA and cosine distance when conducting neural RSA.
rsa_similarity_metric: spearman 
reference_rdm_paths: {
    "behavioral_rdm": "/home/wallacelab/marren/cvpr_old_repo/clip_hba_behavior/Data/RDM48_triplet.mat"
}
reference_rdm_distance_metric: pearson