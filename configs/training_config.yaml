## ---PATHS--- ##
  save_path: "/home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/test" # root path to save training artifacts (checkpoints, training results, random states)
  baseline_checkpoint_path: # path to baseline training run checkpoints used for perturbation sweeps
  img_annotations_file: "./data/spose_embedding66d_rescaled_1806train.csv" # path to the csv file containing the image names and the corresponding target embeddings for the THINGS training data
  img_dir: "/home/wallacelab/investigating-complexity/Images/THINGS" # path to the THINGS image directory

## ---WANDB CONFIGURATION--- ##
  'wandb_project': temporal-dynamics-of-human-alignment # Optional: Name of the WANDB project to use for logging
  'wandb_entity': # Optional: your username or team name

## ---EXPERIMENT SETUP--- ##
  experiment_type: baseline # Required: baseline | perturbation_run

## ---TRAINING PARAMETERS--- ##
  dataset_type: things # Dataset to use for training. "things" for THINGS dataset.
  epochs: 500 # number of epochs to train for
  early_stopping_patience: 20 # number of epochs to wait before stopping training if the validation loss does not improve
  batch_size: 64 # number of training samples to process in each batch
  train_portion: 0.8 # portion of the training data to use for training
  lr: 3e-4 # learning rate for the optimizer
  criterion: MSELoss # loss function to use for training
  random_seed: 1 # random seed to use for training
  cuda: 0 # GPU to use for training; -1 for all GPUs, 0 for GPU 0, 1 for GPU 1, 2 for CPU
  logger: None # Logger to use for training. None for no logging.

## ---PERTURBATION PARAMETERS--- ##
  perturb_type: uniform_images # none | random_target | label_shuffle | image_noise | uniform_images
  perturb_epoch: 0 # epoch to start perturbation (0-indexed)
  perturb_length: 1 # number of epochs to perturb
  perturb_seed: 1 # random seed to use for perturbation

## ---RSA PARAMETERS--- ##
  behavioral_rsa: True # whether to conduct behavioral RSA within the training loop
  rsa_annotations_file: "./data/spose_embedding66d_rescaled_1806train.csv" # path to the csv file containing the image names and the corresponding target embeddings for the THINGS training data
  model_rdm_distance_metric: pearson # distance metric to use for RSA
  rsa_similarity_metric: spearman # similarity metric to use for RSA

## ---MODEL PARAMETERS--- ##
  backbone: ViT-L/14 # model backbone to use for CLIP-HBA
  vision_layers: 2 # number of vision encoder layers to open up for CLIP-HBA training
  transformer_layers: 1 # number of text encoder layers to use for CLIP-HBA training
  rank: 32 # rank of the DoRA layers 