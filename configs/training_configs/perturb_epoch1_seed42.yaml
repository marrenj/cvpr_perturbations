
backbone: ViT-L/14
vision_layers: 2
transformer_layers: 1
rank: 32


epochs: 500
batch_size: 64
train_portion: 0.8
lr: 3e-4
early_stopping_patience: 20
criterion: MSELoss
random_seed: 1
cuda: 0 # -1 for all GPUs, 0 for GPU 0, 1 for GPU 1, 2 for CPU


dataset_type: things
img_annotations_file: clip_hba_behavior/Data/spose_embedding66d_rescaled_1806train.csv # csv data annotations of the training stimuli with the corresponding target embeddings
img_dir: /home/wallacelab/teba/multimodal_brain_inspired/marren/cvpr_perturbations/clip_hba_behavior/Data/Things1854 # path to the image directory
baseline_checkpoint_path: /home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/test/cliphba_baseline_seed1


perturb_type: random_target
perturb_epoch: 1
perturb_length: 1
perturb_seed: 42


logger: None
checkpoint_path: /home/wallacelab/teba/multimodal_brain_inspired/marren/temporal_dynamics_of_human_alignment/test/cliphba_perturb_epoch1_seed42 # path to save the trained model weights